{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_SOCHASTIC",
      "provenance": [],
      "authorship_tag": "ABX9TyORce2S1CMk/N5AlXBkBW0p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3wlsXyDzxQR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import h5py\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpiymSiIz674",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "911e74b7-b92d-4121-8616-cf4c0bb79342"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-094d1087-d0fe-424f-9bb0-8397c792ef61\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-094d1087-d0fe-424f-9bb0-8397c792ef61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.hdf5 to test.hdf5\n",
            "Saving train.hdf5 to train.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAhVlexx0AkE"
      },
      "source": [
        "f1 = h5py.File(\"train.hdf5\", 'r')\n",
        "X_train, Y_train = f1['image'][...], f1['label'][...]\n",
        "\n",
        "f2 = h5py.File(\"test.hdf5\", 'r')\n",
        "X_test, Y_test = f2['image'][...], f2['label'][...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2D9NBlv0RB_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2167f01f-8c9d-41ec-a277-848500c93ff4"
      },
      "source": [
        "X_train = np.array(f1['image'])/255\n",
        "Y_train = np.array([f1['label']])\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_test = np.array(f2['image'])/255\n",
        "Y_test = np.array([f2['label']])\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(1, 60000)\n",
            "(10000, 28, 28)\n",
            "(1, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws8JzBqd0Wph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b4dd96d5-e59a-40f6-af11-38536dc2fa66"
      },
      "source": [
        "X_train = np.reshape(X_train,(60000,784)).T\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_test = np.reshape(X_test,(10000,784)).T\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(1, 60000)\n",
            "(784, 10000)\n",
            "(1, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1FaLf_M0dWd"
      },
      "source": [
        "n_X=X_train.shape[0]\n",
        "m=X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txyAzaa90i4k"
      },
      "source": [
        "shape = (Y_train.max()+1, Y_train.shape[1]) #Generating one_hot_vector so that later we can apply multi class classification\n",
        "one_hot = np.zeros(shape)\n",
        "rows= np.arange(Y_train.shape[1])\n",
        "one_hot[Y_train , rows]=1\n",
        "Y_train = one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfE3qp9AS77s"
      },
      "source": [
        "shape = (Y_test.max()+1, Y_test.shape[1]) #Generating one_hot_vector so that later we can apply multi class classification\n",
        "one_hot = np.zeros(shape)\n",
        "rows= np.arange(Y_test.shape[1])\n",
        "one_hot[Y_test , rows]=1\n",
        "Y_test = one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsF4RtWY04X-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8eaa6b54-c96e-4e90-a783-30f0fad1c862"
      },
      "source": [
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 60000)\n",
            "(10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ2O9UP21AUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b553e025-b93a-4afb-a184-b82d532d0477"
      },
      "source": [
        "n_X=X_train.shape[0]\n",
        "m=X_train.shape[1]\n",
        "\n",
        "def softmax(A):               #Softmax gives a good classification as it standardizes the output values.\n",
        "    A = A - np.max(A)\n",
        "    return np.exp(A) / np.sum(np.exp(A),axis=0) \n",
        "\n",
        "nums = np.array([4, 5, 6])\n",
        "print(softmax(nums))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.09003057 0.24472847 0.66524096]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqtl_Wjj3tM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f0675fa9-7a65-4010-bd29-d6589fdc4226"
      },
      "source": [
        "#def random_mini_batches(X,Y,mini_bactch_size=64):\n",
        "m = X_train.shape[1] \n",
        "mini_batches = []\n",
        "\n",
        "permutation = list(np.random.permutation(m))\n",
        "shuffled_X = X_train[:,permutation]\n",
        "shuffled_Y = Y_train[:,permutation]\n",
        "\n",
        "print(shuffled_X.shape)\n",
        "print(shuffled_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(10, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F10ReHYK596w"
      },
      "source": [
        "def random_mini_batches(X,Y,mini_batch_size=64):\n",
        "  m = X.shape[1] \n",
        "  mini_batches = []\n",
        "\n",
        "  permutation = list(np.random.permutation(m))\n",
        "  shuffled_X = X [:,permutation]\n",
        "  shuffled_Y = Y [:,permutation]\n",
        "\n",
        "  num_comp_batchs = math.floor (m/mini_batch_size)\n",
        "\n",
        "  for i in range (num_comp_batchs):\n",
        "    mini_batch_X = shuffled_X [:, i*mini_batch_size : (i+1)*mini_batch_size ]\n",
        "    mini_batch_Y = shuffled_Y [: ,i*mini_batch_size : (i+1)*mini_batch_size ]\n",
        "\n",
        "    mini_batch = ( mini_batch_X, mini_batch_Y )\n",
        "    mini_batches.append(mini_batch)\n",
        "\n",
        "  if m % mini_batch_size != 0:\n",
        "    end = m - mini_batch_size*math.floor(m/mini_batch_size)\n",
        "    mini_batch_X = shuffled_X [:, num_comp_batchs*mini_batch_size : ]\n",
        "    mini_batch_Y = shuffled_Y [:, num_comp_batchs*mini_batch_size : ]\n",
        "\n",
        "    mini_batch =( mini_batch_X, mini_batch_Y )\n",
        "    mini_batches.append(mini_batch)\n",
        "\n",
        "  return mini_batches\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqBYdeqr1vrE"
      },
      "source": [
        "#initialize_parameters\n",
        "layer_dims=[784,600,400,200,100,50,10]\n",
        "\n",
        "parameters={}\n",
        "L=len(layer_dims)\n",
        "for l in range(1,L):\n",
        "  parameters[\"W\"+str(l)]= np.random.randn(layer_dims[l],layer_dims[l-1])*np.sqrt(2/layer_dims[l-1])\n",
        "\n",
        "  parameters[\"b\"+str(l)]= np.zeros((layer_dims[l],1))*0.01\n",
        "\n",
        "\n",
        "def DNN_model(X,Y,parameters,layer_dims,num_iterations,learning_rate):\n",
        "\n",
        "  m=X.shape[1]\n",
        "  Y_prediction=np.zeros((1,m))\n",
        "  forward_cache={}\n",
        "  \n",
        "  \n",
        "  L=len(layer_dims)\n",
        "  grads={}\n",
        "  costs=[]\n",
        "  cost_1=1000\n",
        "  cost_2=1000\n",
        "  for i in range(0,num_iterations):\n",
        "    mini_batches = random_mini_batches(X,Y,mini_batch_size=64)\n",
        "\n",
        "    for mini_batch in mini_batches:\n",
        "      (mini_batch_X,mini_batch_Y) = mini_batch\n",
        "      forward_cache[\"A0\"]=np.copy(mini_batch_X)\n",
        "    \n",
        "      A=np.copy(mini_batch_X)\n",
        "      for l in range(1,L-1):\n",
        "      \n",
        "        A_prev=np.copy(A)\n",
        "      \n",
        "        forward_cache[\"Z\"+str(l)]=np.dot(parameters[\"W\"+str(l)],A_prev)+parameters[\"b\"+str(l)]\n",
        "        A=np.maximum(0,forward_cache[\"Z\"+str(l)])\n",
        "      \n",
        "        forward_cache[\"A\"+str(l)]=np.copy(A)\n",
        "    #last_layer\n",
        "      W=parameters[\"W\"+str(L-1)]\n",
        "      b=parameters[\"b\"+str(L-1)]\n",
        "      forward_cache[\"Z\"+str(L-1)]=np.dot(W,A)+b\n",
        "      AL_train=  softmax(forward_cache[\"Z\"+str(L-1)])\n",
        "    #compute_cost\n",
        "      m=mini_batch_Y.shape[1]\n",
        "      print(mini_batch_Y.shape,AL_train.shape)\n",
        "      cost_1 = -np.mean(mini_batch_Y * np.log(AL_train + 1e-8))\n",
        "\n",
        "    #print(np.sum(W))\n",
        "    #print(np.sum(b))\n",
        "      print(cost_1)\n",
        "\n",
        "      costs.append(float(cost_1))\n",
        "    #backward_prop\n",
        "      grads[\"dZ\"+str(L-1)]=AL_train-mini_batch_Y\n",
        "      grads[\"dW\"+str(L-1)]=(1/m)*(np.dot(grads[\"dZ\"+str(L-1)],forward_cache[\"A\"+str(L-2)].T))\n",
        "      grads[\"db\"+str(L-1)]=(1/m)*(np.sum(grads[\"dZ\"+str(L-1)],axis=1,keepdims=True))\n",
        "      for l in reversed(range(1,L-1)):\n",
        "        grads[\"dZ\"+str(l)]=np.multiply(np.dot(parameters[\"W\"+str(l+1)].T,grads[\"dZ\"+str(l+1)]),np.int64(forward_cache[\"A\"+str(l)]>0))\n",
        "        grads[\"dW\"+str(l)]=(1/m)*(np.dot(grads[\"dZ\"+str(l)],(forward_cache[\"A\"+str(l-1)]).T))\n",
        "        grads[\"db\"+str(l)]=(1/m)*(np.sum(grads[\"dZ\"+str(l)],axis=1,keepdims=True))\n",
        "      for l in range(1, L):\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads[\"dW\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads[\"db\" + str(l)]\n",
        "     \n",
        "  return parameters,costs,AL_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIx-LrA416z-"
      },
      "source": [
        "parameters,costs,AL_train= DNN_model(X_train,Y_train,parameters,layer_dims,num_iterations=5,learning_rate=0.1)\n",
        "num_iterations=5\n",
        "\n",
        "plt.plot(list(range(len(costs))),list(costs))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxlPSw-419hg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85bb9228-8112-474d-ab45-4f33138271cf"
      },
      "source": [
        "print(AL_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbIbb_9BJf-3"
      },
      "source": [
        "\n",
        "\n",
        "def DNN_model_batch(X,Y,parameters):\n",
        "\n",
        "  m=X.shape[1]\n",
        "  Y_prediction=np.zeros((1,m))\n",
        "  forward_cache={}\n",
        "  \n",
        "  forward_cache[\"A0\"]=np.copy(X)\n",
        "  L=len(layer_dims)\n",
        "  grads={}\n",
        "  costs=[]\n",
        "  cost_1=1000\n",
        "  cost_2=1000\n",
        "  for i in range(0,num_iterations):\n",
        "    \n",
        "    A=np.copy(X)\n",
        "    for l in range(1,L-1):\n",
        "      \n",
        "      A_prev=np.copy(A)\n",
        "      \n",
        "      forward_cache[\"Z\"+str(l)]=np.dot(parameters[\"W\"+str(l)],A_prev)+parameters[\"b\"+str(l)]\n",
        "      A=np.maximum(0,forward_cache[\"Z\"+str(l)])\n",
        "      \n",
        "      forward_cache[\"A\"+str(l)]=np.copy(A)\n",
        "    #last_layer\n",
        "    W=parameters[\"W\"+str(L-1)]\n",
        "    b=parameters[\"b\"+str(L-1)]\n",
        "    forward_cache[\"Z\"+str(L-1)]=np.dot(W,A)+b\n",
        "    AL_train=  softmax(forward_cache[\"Z\"+str(L-1)])\n",
        "     \n",
        "  return parameters,AL_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mndQGg991_cI"
      },
      "source": [
        "  for i in range(AL_train.shape[1]):\n",
        "    \n",
        "    a = np.max(AL_train[:,i])\n",
        "    AL_train[:,i] = (AL_train[:,i]==a)\n",
        "  fai = np.absolute(AL_train - Y_train)\n",
        "  count = 0\n",
        "  for i in range(0,fai.shape[1]):\n",
        "    if np.sum(fai[:,i]) == 0:\n",
        "      count +=1\n",
        "  print(count)\n",
        "  print((count /X_train.shape[1])*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq-bjONL2IA_"
      },
      "source": [
        "#for test set\n",
        "parameters,AL_test= DNN_model_batch(X_test,Y_test,parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-mgRlAn2qma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ff8c8a1-1d02-4d06-8f8e-09b1f8a07645"
      },
      "source": [
        "print(AL_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7_WHZP0VhQf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4ad21492-cc59-43a6-b6c9-b8ba48935a95"
      },
      "source": [
        "  for i in range(AL_test.shape[1]):\n",
        "    \n",
        "    a = np.max(AL_test[:,i])\n",
        "    AL_test[:,i] = (AL_test[:,i]==a)\n",
        "  fai = np.absolute(AL_test - Y_test)\n",
        "  count = 0\n",
        "  for i in range(0,fai.shape[1]):\n",
        "    if np.sum(fai[:,i]) == 0:\n",
        "      count +=1\n",
        "  print(count)\n",
        "  print((count /X_test.shape[1])*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9688\n",
            "96.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KULdHkecWBIO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}